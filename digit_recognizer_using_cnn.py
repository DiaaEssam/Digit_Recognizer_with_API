# -*- coding: utf-8 -*-
"""Digit_Recognizer_Using_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located aty
    https://colab.research.google.com/drive/1l17me2BCc0u6ShzO70DjckJ_5o_SAfP-

<a name='1'></a>
## 1 - Packages
"""

# Commented out IPython magic to ensure Python compatibility.
import math
import numpy as np
import h5py
import matplotlib.pyplot as plt
from matplotlib.pyplot import imread
import scipy
from PIL import Image
import pandas as pd
import tensorflow as tf
from keras.datasets import mnist
import tensorflow.keras.layers as tfl
from tensorflow.python.framework import ops
# %matplotlib inline
np.random.seed(1)

"""<a name='2'></a>
### 2 - Load the SIGNS Dataset

"""

# Loading the data (signs)
(X_train, y_train), (X_test, y_test) = mnist.load_data()

"""# Applying One Hot Encodeing for labels"""

from sklearn.preprocessing import OneHotEncoder

enc = OneHotEncoder()
y_train=enc.fit_transform(y_train.reshape(y_train.shape[0],1)).toarray().astype(int)
y_test=enc.transform(y_test.reshape(y_test.shape[0],1)).toarray().astype(int)

print(y_train.shape)
print(y_train[0])
print(y_test.shape)
print(y_test[0])

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

"""# Normalizing The Data"""

def normalize(X):
  return X/255.0 # we need epsilon for feature (pixel) that has zero variance

X_train = normalize(X_train)
X_test = normalize(X_test)

X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)
X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)


print ("number of training examples = " + str(X_train.shape[0]))
print ("number of test examples = " + str(X_test.shape[0]))
print ("X_train shape: " + str(X_train.shape))
print ("Y_train shape: " + str(y_train.shape))
print ("X_test shape: " + str(X_test.shape))
print ("Y_test shape: " + str(y_test.shape))

"""<a name='3'></a>
### 3 - Forward Propagation


"""

# GRADED FUNCTION: convolutional_model

def arch(input_shape):

    input_img = tf.keras.Input(shape=input_shape)

    Z1=tfl.Conv2D(filters= 6 , kernel_size= 5,strides=(1, 1))(input_img)
    A1=tfl.ReLU()(Z1)
    P1=tfl.AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(A1)
    BT1=tfl.BatchNormalization()(P1, training=True)

    Z2=tfl.Conv2D(filters= 16 , kernel_size= 5 ,strides=(1, 1))(BT1)
    A2=tfl.ReLU()(Z2)
    P2=tfl.AveragePooling2D(pool_size=(5, 5), strides=(2,2))(A2)
    BT2=tfl.BatchNormalization()(P2, training=True)

    F1=tfl.Flatten()(BT2)

    FC1=tfl.Dense(units=120, activation='relu')(F1)
    D1=tfl.Dropout(0.4)(FC1)
    BT3=tfl.BatchNormalization()(D1, training=True)

    FC2=tfl.Dense(units=84, activation='relu')(BT3)
    D2=tfl.Dropout(0.4)(FC2)
    BT4=tfl.BatchNormalization()(D2, training=True)

    outputs=tfl.Dense(units= 10 , activation='softmax')(BT4)
    model = tf.keras.Model(inputs=input_img, outputs=outputs)
    return model

conv_model = arch((28, 28, 1))
conv_model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
conv_model.summary()

"""<a name='4-4'></a>
### 4.4 - Train the Model
"""

train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64)
test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(64)
history = conv_model.fit(train_dataset, epochs=30, validation_data=test_dataset,shuffle=True)

class Sample:

    # function to test a single sample
    def predict(self,image):
        img = Image.open(image).convert('L').resize((28, 28), Image.ANTIALIAS)
        img = np.array(img)
        img = img / 255.

        return np.argmax(tf.nn.softmax(conv_model.predict(img[None,:,:])[0]))

    # function to predict a CSV file
    def predict_file(self,df_test):
        param_X_test=np.array(df_test)
        param_X_test = param_X_test.astype('float32')
        param_X_test=normalize(param_X_test)

        y_pred=conv_model.predict(X_test)
        return np.argmax(y_pred,axis=1)



test_sample=Sample()

# look in the note
import pickle
pickle_out=open("C:/Users/Diaa Essam/OneDrive/Documents/Python/.vscode/Digit_Recognizer_API/Classifier.pkl","wb")
pickle.dump(test_sample, pickle_out)
pickle_out.close()
