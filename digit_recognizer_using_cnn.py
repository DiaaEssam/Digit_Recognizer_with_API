# -*- coding: utf-8 -*-
"""Digit_Recognizer_Using_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located aty
    https://colab.research.google.com/drive/1l17me2BCc0u6ShzO70DjckJ_5o_SAfP-"""



# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from PIL import Image
import tensorflow as tf
from keras.datasets import mnist
import tensorflow.keras.layers as tfl
import os

# %matplotlib inline
np.random.seed(1)


(X_train, y_train), (X_test, y_test) = mnist.load_data()


"""# Applying One Hot Encodeing for labels"""

from sklearn.preprocessing import OneHotEncoder

enc = OneHotEncoder()
y_train=enc.fit_transform(y_train.reshape(y_train.shape[0],1)).toarray().astype(int)
y_test=enc.transform(y_test.reshape(y_test.shape[0],1)).toarray().astype(int)

print(y_train.shape)
print(y_train[0])
print(y_test.shape)
print(y_test[0])

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

"""# Normalizing The Data"""

def normalize(X):
  return X/255.0 # we need epsilon for feature (pixel) that has zero variance

X_train = normalize(X_train)
X_test = normalize(X_test)

X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)
X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)


print ("number of training examples = " + str(X_train.shape[0]))
print ("number of test examples = " + str(X_test.shape[0]))
print ("X_train shape: " + str(X_train.shape))
print ("Y_train shape: " + str(y_train.shape))
print ("X_test shape: " + str(X_test.shape))
print ("Y_test shape: " + str(y_test.shape))

"""<a name='3'></a>
### 3 - Forward Propagation


"""


def arch(input_shape):

    input_img = tf.keras.Input(shape=input_shape)

    layer=tfl.Conv2D(filters= 6 , kernel_size= 5,strides=(1, 1))(input_img)
    layer=tfl.ReLU()(layer)
    layer=tfl.AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(layer)

    layer=tfl.Conv2D(filters= 16 , kernel_size= 5 ,strides=(1, 1))(layer)
    layer=tfl.ReLU()(layer)
    layer=tfl.AveragePooling2D(pool_size=(5, 5), strides=(2,2))(layer)

    layer=tfl.Flatten()(layer)

    layer=tfl.Dense(units=120, activation='relu')(layer)

    layer=tfl.Dense(units=84, activation='relu')(layer)

    outputs=tfl.Dense(units= 10 , activation='softmax')(layer)
    model = tf.keras.Model(inputs=input_img, outputs=outputs)
    return model

conv_model = arch((28, 28, 1))
conv_model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
conv_model.summary()

"""<a name='4-4'></a>
### 4.4 - Train the Model
"""

train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64)
test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(64)
history = conv_model.fit(train_dataset, epochs=30, validation_data=test_dataset,shuffle=True)

class Sample:

    # function to test a single sample
    def predict(self,image):
        image = Image.open(image)
        image = image.convert('L')
        image = np.array(image.resize((28, 28)))
        image = image.astype('float32')
        image = image / 255.
        image = image.reshape((1, 28, 28,1))

        return np.argmax(tf.nn.softmax(conv_model.predict(image)[0]))

    # function to predict a CSV file
    def predict_file(self,df_test):
        param_X_test=np.array(df_test)
        param_X_test = param_X_test.astype('float32')
        param_X_test=normalize(param_X_test)

        y_pred=conv_model.predict(X_test)
        return np.argmax(y_pred,axis=1)



test_sample=Sample()

current_directory = os.path.abspath(os.path.dirname(__file__))
pickle_file_path = os.path.join(current_directory, "Classifier.pkl")

import pickle
pickle_out=open(pickle_file_path,"wb")
pickle.dump(test_sample, pickle_out)
pickle_out.close()
